//! LLM è‡ªåŠ¨æ›´æ­£æ¨¡å—
//! 
//! ä½¿ç”¨ SiliconFlow API è‡ªåŠ¨æ›´æ­£æ‹¼å†™é”™è¯¯çš„å•è¯

use crate::{Error, Result, EnvLoader};
use reqwest::blocking::Client;
use serde::{Deserialize, Serialize};
use serde_json::json;

/// LLM æ›´æ­£å™¨
pub struct LLMCorrector {
    client: Client,
    api_key: Option<String>,
    base_url: String,
    model: String,
}

/// æ›´æ­£ç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CorrectionResult {
    pub success: bool,
    pub original: String,
    pub corrected: String,
    pub confidence: String,
    pub reason: String,
}

/// å€™é€‰è¯ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Candidate {
    pub word: String,
    pub reason: String,
    pub verified: bool,
}

/// å€™é€‰è¯ç”Ÿæˆç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CandidatesResult {
    pub success: bool,
    pub original: String,
    pub candidates: Vec<Candidate>,
    pub reason: String,
}

/// API å“åº”ç»“æ„
#[derive(Debug, Deserialize)]
struct ApiResponse {
    choices: Vec<Choice>,
}

#[derive(Debug, Deserialize)]
struct Choice {
    message: Message,
}

#[derive(Debug, Deserialize)]
struct Message {
    content: String,
}

/// LLM å“åº”ç»“æ„
#[derive(Debug, Deserialize)]
struct LLMCorrectionResponse {
    corrected: String,
    confidence: String,
    reason: String,
}

#[derive(Debug, Deserialize)]
struct LLMCandidatesResponse {
    candidates: Vec<CandidateInfo>,
}

#[derive(Debug, Deserialize)]
struct CandidateInfo {
    word: String,
    reason: String,
}

impl LLMCorrector {
    /// åˆ›å»ºæ–°çš„ LLM æ›´æ­£å™¨
    pub fn new() -> Result<Self> {
        let api_key = EnvLoader::get_optional("SILICONFLOW_API_KEY");
        
        if api_key.is_none() {
            log::warn!("âš ï¸  æœªè®¾ç½® SILICONFLOW_API_KEYï¼ŒLLMè‡ªåŠ¨æ›´æ­£åŠŸèƒ½å°†è¢«ç¦ç”¨");
            log::warn!("ğŸ’¡ åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ : SILICONFLOW_API_KEY=your_key_here");
            log::warn!("   è·å–åœ°å€: https://cloud.siliconflow.cn/");
        }
        
        let base_url = EnvLoader::get(
            "SILICONFLOW_BASE_URL",
            Some("https://api.siliconflow.cn/v1/chat/completions"),
        )?;
        
        let model = EnvLoader::get(
            "SILICONFLOW_MODEL",
            Some("Qwen/Qwen2.5-7B-Instruct"),
        )?;
        
        let client = Client::builder()
            .timeout(std::time::Duration::from_secs(30))
            .build()?;
        
        Ok(Self {
            client,
            api_key,
            base_url,
            model,
        })
    }
    
    /// æ£€æŸ¥ LLM åŠŸèƒ½æ˜¯å¦å¯ç”¨
    pub fn is_enabled(&self) -> bool {
        self.api_key.is_some()
    }
    
    /// æ›´æ­£å•è¯
    pub fn correct_word(&self, word: &str, meaning: &str) -> Result<CorrectionResult> {
        if !self.is_enabled() {
            return Ok(CorrectionResult {
                success: false,
                original: word.to_string(),
                corrected: word.to_string(),
                confidence: "none".to_string(),
                reason: "LLMåŠŸèƒ½æœªå¯ç”¨".to_string(),
            });
        }
        
        let prompt = format!(
            r#"è¯·æ£€æŸ¥ä»¥ä¸‹è‹±è¯­å•è¯æ˜¯å¦æœ‰æ‹¼å†™é”™è¯¯ï¼Œå¦‚æœæœ‰é”™è¯¯è¯·ç»™å‡ºæ­£ç¡®çš„æ‹¼å†™ã€‚

åŸå§‹å•è¯: {}
ä¸­æ–‡é‡Šä¹‰: {}

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- corrected: æ›´æ­£åçš„å•è¯ï¼ˆå¦‚æœæ²¡æœ‰é”™è¯¯åˆ™è¿”å›åŸå•è¯ï¼‰
- confidence: ç½®ä¿¡åº¦ï¼Œå¯é€‰å€¼ä¸º "high"ï¼ˆé«˜ï¼‰ã€"medium"ï¼ˆä¸­ï¼‰ã€"low"ï¼ˆä½ï¼‰
- reason: ç®€çŸ­è¯´æ˜æ›´æ­£çš„åŸå› æˆ–åˆ¤æ–­æ²¡æœ‰é”™è¯¯çš„ä¾æ®

ç¤ºä¾‹è¾“å‡ºï¼š
{{"corrected": "example", "confidence": "high", "reason": "åŸå•è¯æ‹¼å†™æ­£ç¡®"}}
æˆ–
{{"corrected": "receive", "confidence": "high", "reason": "ä¿®æ­£äº†iå’Œeçš„é¡ºåº"}}

åªè¿”å›JSONï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚"#,
            word, meaning
        );
        
        let response = self.call_llm(&prompt)?;
        self.parse_correction_response(word, &response)
    }
    
    /// ç”Ÿæˆå€™é€‰è¯
    pub fn generate_candidates(&self, word: &str, meaning: &str) -> Result<CandidatesResult> {
        if !self.is_enabled() {
            return Ok(CandidatesResult {
                success: false,
                original: word.to_string(),
                candidates: vec![],
                reason: "LLMåŠŸèƒ½æœªå¯ç”¨".to_string(),
            });
        }
        
        let prompt = format!(
            r#"å¯¹äºæ— æ³•è¯†åˆ«çš„è‹±è¯­å•è¯"{}"ï¼ˆé‡Šä¹‰ï¼š{}ï¼‰ï¼Œè¯·ç”Ÿæˆ3-5ä¸ªå¯èƒ½çš„å€™é€‰è¯ã€‚

å€™é€‰è¯å¯ä»¥æ˜¯ï¼š
1. è¯¥å•è¯çš„è¯æ ¹æˆ–åŸºç¡€å½¢å¼
2. è¯¥å•è¯å»æ‰å‰ç¼€/åç¼€åçš„å½¢å¼
3. æ„æ€ç›¸è¿‘çš„å¸¸è§å•è¯
4. å¯èƒ½çš„æ­£ç¡®æ‹¼å†™ï¼ˆå¦‚æœåŸè¯æœ‰æ‹¼å†™é”™è¯¯ï¼‰

è¦æ±‚ï¼š
- å€™é€‰è¯å¿…é¡»æ˜¯çœŸå®å­˜åœ¨çš„å¸¸è§è‹±è¯­å•è¯
- ä¼˜å…ˆé€‰æ‹©æ›´åŸºç¡€ã€æ›´å¸¸ç”¨çš„è¯æ±‡
- ä¿æŒä¸åŸé‡Šä¹‰çš„ç›¸å…³æ€§

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«ï¼š
- candidates: å€™é€‰è¯åˆ—è¡¨ï¼ˆæ¯ä¸ªåŒ…å«wordå’Œreasonå­—æ®µï¼‰

ç¤ºä¾‹è¾“å‡ºï¼š
{{
  "candidates": [
    {{"word": "system", "reason": "supersystemçš„è¯æ ¹"}},
    {{"word": "efficient", "reason": "ineffectivelyçš„åä¹‰è¯æ ¹"}},
    {{"word": "finance", "reason": "finanziallyçš„è¯æ ¹"}}
  ]
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"#,
            word, meaning
        );
        
        let response = self.call_llm(&prompt)?;
        self.parse_candidates_response(word, &response)
    }
    
    /// è°ƒç”¨ LLM API
    fn call_llm(&self, prompt: &str) -> Result<String> {
        let api_key = self.api_key.as_ref().ok_or_else(|| 
            Error::EnvVar("SILICONFLOW_API_KEY æœªè®¾ç½®".to_string())
        )?;
        
        let payload = json!({
            "model": self.model,
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‹±è¯­å•è¯æ‹¼å†™æ£€æŸ¥åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯è¯†åˆ«å’Œä¿®æ­£è‹±è¯­å•è¯ä¸­çš„æ‹¼å†™é”™è¯¯ã€‚åªè¿”å›JSONæ ¼å¼çš„ç»“æœã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.3,
            "max_tokens": 200
        });
        
        let response = self
            .client
            .post(&self.base_url)
            .header("Authorization", format!("Bearer {}", api_key))
            .header("Content-Type", "application/json")
            .json(&payload)
            .send()?;
        
        if !response.status().is_success() {
            return Err(Error::Other(format!(
                "LLM API è¯·æ±‚å¤±è´¥: HTTP {}",
                response.status()
            )));
        }
        
        let api_response: ApiResponse = response.json()?;
        
        api_response
            .choices
            .first()
            .map(|c| c.message.content.clone())
            .ok_or_else(|| Error::Other("LLM å“åº”ä¸ºç©º".to_string()))
    }
    
    /// è§£ææ›´æ­£å“åº”
    fn parse_correction_response(&self, original: &str, content: &str) -> Result<CorrectionResult> {
        let content = content.trim();
        
        // æå– JSONï¼ˆå¯èƒ½åŒ…å«åœ¨ä»£ç å—ä¸­ï¼‰
        let json_content = if content.contains("```json") {
            content
                .split("```json")
                .nth(1)
                .and_then(|s| s.split("```").next())
                .unwrap_or(content)
                .trim()
        } else if content.contains("```") {
            content
                .split("```")
                .nth(1)
                .and_then(|s| s.split("```").next())
                .unwrap_or(content)
                .trim()
        } else {
            content
        };
        
        match serde_json::from_str::<LLMCorrectionResponse>(json_content) {
            Ok(resp) => Ok(CorrectionResult {
                success: true,
                original: original.to_string(),
                corrected: resp.corrected,
                confidence: resp.confidence,
                reason: resp.reason,
            }),
            Err(_) => {
                // å°è¯•ä»æ–‡æœ¬ä¸­æå–å•è¯
                let words: Vec<&str> = content.split_whitespace().collect();
                if let Some(word) = words.first() {
                    Ok(CorrectionResult {
                        success: true,
                        original: original.to_string(),
                        corrected: word.trim_matches(|c: char| !c.is_alphabetic()).to_string(),
                        confidence: "low".to_string(),
                        reason: "ä»å“åº”ä¸­æå–çš„å•è¯".to_string(),
                    })
                } else {
                    Ok(CorrectionResult {
                        success: false,
                        original: original.to_string(),
                        corrected: original.to_string(),
                        confidence: "none".to_string(),
                        reason: "æ— æ³•è§£æLLMå“åº”".to_string(),
                    })
                }
            }
        }
    }
    
    /// è§£æå€™é€‰è¯å“åº”
    fn parse_candidates_response(&self, original: &str, content: &str) -> Result<CandidatesResult> {
        let content = content.trim();
        
        // æå– JSON
        let json_content = if content.contains("```json") {
            content
                .split("```json")
                .nth(1)
                .and_then(|s| s.split("```").next())
                .unwrap_or(content)
                .trim()
        } else if content.contains("```") {
            content
                .split("```")
                .nth(1)
                .and_then(|s| s.split("```").next())
                .unwrap_or(content)
                .trim()
        } else {
            content
        };
        
        match serde_json::from_str::<LLMCandidatesResponse>(json_content) {
            Ok(resp) => {
                let candidates = resp
                    .candidates
                    .into_iter()
                    .map(|c| Candidate {
                        word: c.word,
                        reason: c.reason,
                        verified: false,
                    })
                    .collect();
                
                Ok(CandidatesResult {
                    success: true,
                    original: original.to_string(),
                    candidates,
                    reason: "success".to_string(),
                })
            }
            Err(e) => Ok(CandidatesResult {
                success: false,
                original: original.to_string(),
                candidates: vec![],
                reason: format!("è§£æå“åº”å¤±è´¥: {}", e),
            }),
        }
    }
}

impl Default for LLMCorrector {
    fn default() -> Self {
        Self::new().expect("åˆ›å»º LLMCorrector å¤±è´¥")
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_corrector_creation() {
        let corrector = LLMCorrector::new();
        assert!(corrector.is_ok());
    }
}

