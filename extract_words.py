#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä»markdownæ ¼å¼çš„å•è¯æœ¬ä¸­æå–å•è¯
"""

import re
import os
import sys
from bs4 import BeautifulSoup
import argparse
from pathlib import Path
import requests
import json
import time


class BBDCWordChecker:
    """ä¸èƒŒå•è¯è¯ä¹¦æ ¸å¯¹ç±»"""
    
    def __init__(self):
        self.submit_url = "https://bbdc.cn/lexis/book/file/submit"
        self.session = requests.Session()
        
        # è®¾ç½®è¯·æ±‚å¤´
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36 Edg/141.0.0.0',
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6,zh-TW;q=0.5',
            'Accept-Encoding': 'gzip, deflate, br, zstd',
            'Origin': 'https://bbdc.cn',
            'Referer': 'https://bbdc.cn/lexis_book_index',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-origin',
            'X-Requested-With': 'XMLHttpRequest',
            'Connection': 'keep-alive'
        })
    
    def upload_word_file(self, file_path, filename=None):
        """ä¸Šä¼ å•è¯æ–‡ä»¶è¿›è¡Œæ ¸å¯¹"""
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        if not filename:
            filename = os.path.basename(file_path)
        
        try:
            with open(file_path, 'rb') as f:
                files = {
                    'file': (filename, f, 'text/plain')
                }
                
                response = self.session.post(
                    self.submit_url,
                    files=files,
                    timeout=30
                )
            
            if response.status_code == 200:
                try:
                    return response.json()
                except json.JSONDecodeError:
                    return {"error": "Invalid JSON response", "content": response.text}
            else:
                return {"error": f"HTTP {response.status_code}", "content": response.text}
                
        except requests.exceptions.Timeout:
            return {"error": "Request timeout"}
        except requests.exceptions.RequestException as e:
            return {"error": str(e)}
    
    def parse_result(self, result):
        """è§£ææ ¸å¯¹ç»“æœ"""
        if "error" in result:
            return result
        
        try:
            data_body = result.get("data_body", {})
            unknow_list = data_body.get("unknowList", "")
            know_list = data_body.get("knowList", "")
            
            # åˆ†å‰²å•è¯åˆ—è¡¨
            unrecognized_words = [word.strip() for word in unknow_list.split(',') if word.strip()]
            recognized_words = [word.strip() for word in know_list.split(',') if word.strip()]
            
            return {
                "unrecognized_words": unrecognized_words,
                "recognized_words": recognized_words,
                "unrecognized_count": len(unrecognized_words),
                "recognized_count": len(recognized_words),
                "total_count": len(unrecognized_words) + len(recognized_words)
            }
        except Exception as e:
            return {"error": f"è§£æç»“æœå¤±è´¥: {e}"}


def find_word_info_in_markdown(file_path, word):
    """
    åœ¨markdownæ–‡ä»¶ä¸­æŸ¥æ‰¾å•è¯çš„è¡Œå·å’Œå«ä¹‰
    
    å‚æ•°:
        file_path: markdownæ–‡ä»¶è·¯å¾„
        word: è¦æŸ¥æ‰¾çš„å•è¯
    
    è¿”å›:
        dict: åŒ…å«è¡Œå·å’Œå«ä¹‰çš„å­—å…¸
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        soup = BeautifulSoup(''.join(lines), 'html.parser')
        tables = soup.find_all('table')
        
        for table in tables:
            rows = table.find_all('tr')
            for row in rows:
                cols = row.find_all('td')
                if len(cols) >= 3:
                    word_text = cols[1].get_text(strip=True)
                    if word_text.lower() == word.lower():
                        meaning = cols[2].get_text(strip=True)
                        # æŸ¥æ‰¾åŸå§‹è¡Œå·
                        row_html = str(row)
                        for i, line in enumerate(lines):
                            if row_html in line:
                                return {
                                    'line_number': i + 1,
                                    'meaning': meaning,
                                    'word': word_text
                                }
        
        return None
    except Exception as e:
        print(f"æŸ¥æ‰¾å•è¯ {word} ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        return None


def check_words_with_bbdc(file_path, words_list, original_md_file):
    """
    ä½¿ç”¨ä¸èƒŒå•è¯æ ¸å¯¹å•è¯åˆ—è¡¨
    
    å‚æ•°:
        file_path: ä¸´æ—¶å•è¯æ–‡ä»¶è·¯å¾„
        words_list: å•è¯åˆ—è¡¨
        original_md_file: åŸå§‹markdownæ–‡ä»¶è·¯å¾„
    
    è¿”å›:
        dict: æ ¸å¯¹ç»“æœ
    """
    print("\nğŸ”„ æ­£åœ¨ä½¿ç”¨ä¸èƒŒå•è¯æ ¸å¯¹å•è¯...")
    
    checker = BBDCWordChecker()
    result = checker.upload_word_file(file_path)
    
    if "error" in result:
        print(f"âŒ æ ¸å¯¹å¤±è´¥: {result['error']}")
        return None
    
    parsed_result = checker.parse_result(result)
    
    if "error" in parsed_result:
        print(f"âŒ è§£æç»“æœå¤±è´¥: {parsed_result['error']}")
        return None
    
    # ä¸ºè¯†åˆ«ä¸æˆåŠŸçš„å•è¯æŸ¥æ‰¾è¯¦ç»†ä¿¡æ¯
    unrecognized_details = []
    for word in parsed_result['unrecognized_words']:
        word_info = find_word_info_in_markdown(original_md_file, word)
        if word_info:
            unrecognized_details.append(word_info)
        else:
            unrecognized_details.append({
                'line_number': 'æœªçŸ¥',
                'meaning': 'æœªæ‰¾åˆ°',
                'word': word
            })
    
    parsed_result['unrecognized_details'] = unrecognized_details
    parsed_result['original_file'] = original_md_file
    return parsed_result


def extract_words_from_markdown(file_path, output_file=None, include_phrases=False):
    """
    ä»markdownæ–‡ä»¶ä¸­æå–å•è¯
    
    å‚æ•°:
        file_path: markdownæ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        include_phrases: æ˜¯å¦åŒ…å«çŸ­è¯­ï¼ˆé»˜è®¤Falseï¼‰
    
    è¿”å›:
        words_list: æå–çš„å•è¯åˆ—è¡¨
    """
    # è¯»å–æ–‡ä»¶
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ä½¿ç”¨BeautifulSoupè§£æHTMLè¡¨æ ¼
    soup = BeautifulSoup(content, 'html.parser')
    
    # æŸ¥æ‰¾æ‰€æœ‰è¡¨æ ¼
    tables = soup.find_all('table')
    
    words_data = []  # å­˜å‚¨å•è¯åŠå…¶ä¿¡æ¯
    phrases_data = []  # å­˜å‚¨çŸ­è¯­åŠå…¶ä¿¡æ¯
    
    for table in tables:
        rows = table.find_all('tr')
        
        # è·³è¿‡è¡¨å¤´å’Œç©ºè¡Œ
        is_phrase_table = False
        for row in rows:
            cols = row.find_all('td')
            
            # è‡³å°‘éœ€è¦3åˆ—ï¼šåºå·ã€å•è¯/çŸ­è¯­ã€è¯ä¹‰
            if len(cols) >= 3:
                # æ£€æŸ¥æ˜¯å¦æ˜¯è¡¨å¤´
                col1_text = cols[0].get_text(strip=True)
                col2_text = cols[1].get_text(strip=True)
                
                # è·³è¿‡è¡¨å¤´è¡Œå’Œè¡¥å……åŒº
                if col1_text in ['NO.', ''] or 'è¡¥å……åŒº' in col1_text:
                    continue
                
                # åˆ¤æ–­æ˜¯çŸ­è¯­è¡¨è¿˜æ˜¯å•è¯è¡¨
                if col2_text in ['å•è¯', 'çŸ­è¯­']:
                    if col2_text == 'çŸ­è¯­':
                        is_phrase_table = True
                    continue
                
                # æå–æ•°æ®
                try:
                    number = col1_text
                    word_or_phrase = col2_text
                    meaning = cols[2].get_text(strip=True)
                    
                    # è·³è¿‡ç©ºè¡Œæˆ–æ— æ•ˆæ•°æ®
                    if not word_or_phrase or not number.isdigit():
                        continue
                    
                    # åˆ¤æ–­æ˜¯å•è¯è¿˜æ˜¯çŸ­è¯­ï¼ˆé€šè¿‡ç©ºæ ¼åˆ¤æ–­ï¼‰
                    if ' ' in word_or_phrase or '-' in word_or_phrase:
                        phrases_data.append({
                            'number': number,
                            'phrase': word_or_phrase,
                            'meaning': meaning
                        })
                    else:
                        words_data.append({
                            'number': number,
                            'word': word_or_phrase,
                            'meaning': meaning
                        })
                except:
                    continue
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"æå–åˆ° {len(words_data)} ä¸ªå•è¯")
    print(f"æå–åˆ° {len(phrases_data)} ä¸ªçŸ­è¯­")
    
    # ä¿å­˜ç»“æœ
    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            # å†™å…¥å•è¯
            f.write("=" * 50 + "\n")
            f.write("å•è¯åˆ—è¡¨\n")
            f.write("=" * 50 + "\n\n")
            for item in words_data:
                f.write(f"{item['number']}. {item['word']}\t{item['meaning']}\n")
            
            if include_phrases:
                f.write("\n" + "=" * 50 + "\n")
                f.write("çŸ­è¯­åˆ—è¡¨\n")
                f.write("=" * 50 + "\n\n")
                for item in phrases_data:
                    f.write(f"{item['number']}. {item['phrase']}\t{item['meaning']}\n")
        
        print(f"\nç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    # è¿”å›ç»“æœ
    if include_phrases:
        return words_data, phrases_data
    else:
        return words_data


def extract_words_only(file_path, output_file=None, unique=True, auto_check=True):
    """
    ä»…æå–å•è¯ï¼ˆä¸åŒ…å«è¯ä¹‰ï¼‰ï¼Œæ¯è¡Œä¸€ä¸ªå•è¯
    
    å‚æ•°:
        file_path: markdownæ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        unique: æ˜¯å¦å»é‡ï¼ˆé»˜è®¤Trueï¼‰
        auto_check: æ˜¯å¦è‡ªåŠ¨è¿›è¡Œä¸èƒŒå•è¯æ ¸å¯¹ï¼ˆé»˜è®¤Trueï¼‰
    
    è¿”å›:
        words_list: å•è¯åˆ—è¡¨
    """
    words_data = extract_words_from_markdown(file_path)
    
    # æå–æ‰€æœ‰å•è¯
    words_list = [item['word'] for item in words_data]
    
    # å»é‡ï¼ˆä¿æŒé¡ºåºï¼‰
    if unique:
        seen = set()
        unique_words = []
        for word in words_list:
            if word.lower() not in seen:
                seen.add(word.lower())
                unique_words.append(word)
        words_list = unique_words
        print(f"å»é‡åå‰©ä½™ {len(words_list)} ä¸ªå•è¯")
    
    # ä¿å­˜ç»“æœ
    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            for word in words_list:
                f.write(word + '\n')
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # è‡ªåŠ¨è¿›è¡Œä¸èƒŒå•è¯æ ¸å¯¹
        if auto_check and len(words_list) > 0:
            check_result = check_words_with_bbdc(output_file, words_list, file_path)
            if check_result:
                print_check_result(check_result, output_file)
    
    return words_list


def print_check_result(check_result, output_file):
    """
    æ‰“å°ä¸èƒŒå•è¯æ ¸å¯¹ç»“æœ
    
    å‚æ•°:
        check_result: æ ¸å¯¹ç»“æœ
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    print("\n" + "=" * 60)
    print("ğŸ“Š ä¸èƒŒå•è¯è¯ä¹¦æ ¸å¯¹ç»“æœ")
    print("=" * 60)
    
    print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  æ€»å•è¯æ•°: {check_result['total_count']}")
    print(f"  è¯†åˆ«æˆåŠŸ: {check_result['recognized_count']}")
    print(f"  è¯†åˆ«ä¸æˆåŠŸ: {check_result['unrecognized_count']}")
    print(f"  è¯†åˆ«æˆåŠŸç‡: {check_result['recognized_count']/check_result['total_count']*100:.1f}%")
    
    # æ˜¾ç¤ºè¯†åˆ«æˆåŠŸçš„å•è¯ï¼ˆå‰10ä¸ªï¼‰
    if check_result['recognized_words']:
        print(f"\nâœ… è¯†åˆ«æˆåŠŸçš„å•è¯ï¼ˆå‰10ä¸ªï¼‰:")
        for i, word in enumerate(check_result['recognized_words'][:10], 1):
            print(f"  {i:2d}. {word}")
        
        if len(check_result['recognized_words']) > 10:
            print(f"  ... è¿˜æœ‰ {len(check_result['recognized_words']) - 10} ä¸ªè¯†åˆ«æˆåŠŸçš„å•è¯")
    
    # æ˜¾ç¤ºè¯†åˆ«ä¸æˆåŠŸçš„å•è¯ï¼ˆè¯¦ç»†ä¿¡æ¯ï¼‰
    if check_result['unrecognized_details']:
        source_file = os.path.basename(check_result.get('original_file', 'æœªçŸ¥æ–‡ä»¶'))
        word_file = os.path.basename(output_file)
        print(f"\n\næ£€æŸ¥è¿™äº›å•è¯æ˜¯å¦æœ‰è¯¯,ä½ å¯ä»¥é€šè¿‡æ ‡æ˜çš„è¡Œæ•°ç›´æ¥é˜…è¯»è¯¥è¡Œå‰åä»¥ç¡®å®šå…¶ä½ç½®ï¼Œä¸ç”¨é˜…è¯»æ•´ä¸ªæ–‡ä»¶,å¦‚æœå‘ç°é”™åˆ«å­—ç­‰æƒ…å†µã€è¯·è¯¢é—®æˆ‘å¾—åˆ°åŒæ„åï¼Œå¯¹å•è¯æ–‡æœ¬æ–‡ä»¶è¿›è¡Œä¿®æ­£ã€‚\n è¯†åˆ«ä¸æˆåŠŸçš„å•è¯ï¼ˆè¯¦ç»†ä¿¡æ¯ï¼‰,æºæ–‡ä»¶ã€{source_file}ã€‘ï¼Œå•è¯æ–‡æœ¬æ–‡ä»¶ã€{word_file}ã€‘:")
        for i, detail in enumerate(check_result['unrecognized_details'], 1):
            print(f"  {i:2d}. {detail['word']:<15} ç¬¬{detail['line_number']}è¡Œ  {detail['meaning']}")
    
    # è¯¢é—®æ˜¯å¦ä¿å­˜è¯¦ç»†ç»“æœ
    save_choice = input("\nğŸ’¾ æ˜¯å¦ä¿å­˜è¯¦ç»†ç»“æœåˆ°æ–‡ä»¶ï¼Ÿ(y/n): ").strip().lower()
    if save_choice == 'y':
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        detail_output = f"bbdc_check_detail_{timestamp}.txt"
        
        try:
            with open(detail_output, 'w', encoding='utf-8') as f:
                f.write("=" * 60 + "\n")
                f.write("ä¸èƒŒå•è¯è¯ä¹¦æ ¸å¯¹è¯¦ç»†ç»“æœ\n")
                f.write("=" * 60 + "\n\n")
                
                f.write(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:\n")
                f.write(f"  æ€»å•è¯æ•°: {check_result['total_count']}\n")
                f.write(f"  è¯†åˆ«æˆåŠŸ: {check_result['recognized_count']}\n")
                f.write(f"  è¯†åˆ«ä¸æˆåŠŸ: {check_result['unrecognized_count']}\n")
                f.write(f"  è¯†åˆ«æˆåŠŸç‡: {check_result['recognized_count']/check_result['total_count']*100:.1f}%\n\n")
                
                f.write("=" * 30 + " è¯†åˆ«æˆåŠŸçš„å•è¯ " + "=" * 30 + "\n")
                for i, word in enumerate(check_result['recognized_words'], 1):
                    f.write(f"{i:3d}. {word}\n")
                
                f.write("\n" + "=" * 30 + " è¯†åˆ«ä¸æˆåŠŸçš„å•è¯ï¼ˆè¯¦ç»†ä¿¡æ¯ï¼‰ " + "=" * 30 + "\n")
                f.write(f"æºæ–‡ä»¶: {os.path.basename(check_result.get('original_file', 'æœªçŸ¥æ–‡ä»¶'))}\n")
                f.write(f"å•è¯æ–‡æœ¬æ–‡ä»¶: {os.path.basename(output_file)}\n\n")
                for i, detail in enumerate(check_result['unrecognized_details'], 1):
                    f.write(f"{i:3d}. {detail['word']:<20} ç¬¬{detail['line_number']}è¡Œ  {detail['meaning']}\n")
            
            print(f"ğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {detail_output}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜è¯¦ç»†ç»“æœå¤±è´¥: {e}")


def print_header():
    """æ‰“å°ç¨‹åºå¤´éƒ¨"""
    print("\n" + "=" * 60)
    print("           ğŸ“š å•è¯æå–å·¥å…· - Word Extractor")
    print("=" * 60)
    print()


def print_menu():
    """æ‰“å°ä¸»èœå•"""
    print("\nè¯·é€‰æ‹©æ“ä½œæ¨¡å¼ï¼š")
    print("  [1] æå–å•è¯ï¼ˆä»…å•è¯ï¼Œæ¯è¡Œä¸€ä¸ªï¼‰+ è‡ªåŠ¨æ ¸å¯¹")
    print("  [2] æå–å•è¯ï¼ˆåŒ…å«è¯ä¹‰ï¼‰")
    print("  [3] æå–å•è¯å’ŒçŸ­è¯­ï¼ˆåŒ…å«è¯ä¹‰ï¼‰")
    print("  [4] æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶")
    print("  [0] é€€å‡º")
    print()


def get_choice(prompt, valid_choices):
    """è·å–ç”¨æˆ·é€‰æ‹©"""
    while True:
        choice = input(prompt).strip()
        if choice in valid_choices:
            return choice
        print(f"âŒ æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·è¾“å…¥ {', '.join(valid_choices)} ä¸­çš„ä¸€ä¸ª")


def get_input_file():
    """è·å–è¾“å…¥æ–‡ä»¶è·¯å¾„"""
    print("\nğŸ“‚ è¯·è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼š")
    print("  æç¤ºï¼šå¯ä»¥ç›´æ¥æ‹–æ‹½æ–‡ä»¶åˆ°æ­¤çª—å£ï¼Œæˆ–è¾“å…¥å®Œæ•´è·¯å¾„")
    
    while True:
        file_path = input("æ–‡ä»¶è·¯å¾„: ").strip().strip('"').strip("'")
        
        if not file_path:
            print("âŒ è·¯å¾„ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥")
            continue
        
        if not os.path.exists(file_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            retry = input("æ˜¯å¦é‡æ–°è¾“å…¥ï¼Ÿ(y/n): ").strip().lower()
            if retry != 'y':
                return None
            continue
        
        if not file_path.endswith('.md'):
            print("âš ï¸  è­¦å‘Šï¼šæ–‡ä»¶ä¸æ˜¯ .md æ ¼å¼ï¼Œæ˜¯å¦ç»§ç»­ï¼Ÿ(y/n): ", end='')
            if input().strip().lower() != 'y':
                continue
        
        return file_path


def get_output_file(default_name):
    """è·å–è¾“å‡ºæ–‡ä»¶è·¯å¾„"""
    print(f"\nğŸ’¾ è¾“å‡ºæ–‡ä»¶åï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤: {default_name}ï¼‰: ", end='')
    output = input().strip().strip('"').strip("'")
    
    if not output:
        return default_name
    
    # ç¡®ä¿æœ‰æ–‡ä»¶æ‰©å±•å
    if not output.endswith('.txt'):
        output += '.txt'
    
    # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè¯¢é—®æ˜¯å¦è¦†ç›–
    if os.path.exists(output):
        print(f"âš ï¸  æ–‡ä»¶ {output} å·²å­˜åœ¨ï¼Œæ˜¯å¦è¦†ç›–ï¼Ÿ(y/n): ", end='')
        if input().strip().lower() != 'y':
            return get_output_file(default_name)
    
    return output


def preview_results(words_data, phrases_data=None, limit=10):
    """é¢„è§ˆæå–ç»“æœ"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ æå–ç»“æœé¢„è§ˆï¼ˆå‰ {} é¡¹ï¼‰".format(limit))
    print("=" * 60)
    
    if words_data:
        print("\nã€å•è¯ã€‘")
        for i, item in enumerate(words_data[:limit], 1):
            if isinstance(item, dict):
                word = item.get('word', '')
                meaning = item.get('meaning', '')
                print(f"  {i}. {word:<20} {meaning}")
            else:
                print(f"  {i}. {item}")
        
        if len(words_data) > limit:
            print(f"  ... è¿˜æœ‰ {len(words_data) - limit} ä¸ªå•è¯æœªæ˜¾ç¤º")
    
    if phrases_data:
        print("\nã€çŸ­è¯­ã€‘")
        for i, item in enumerate(phrases_data[:limit], 1):
            phrase = item.get('phrase', '')
            meaning = item.get('meaning', '')
            print(f"  {i}. {phrase:<30} {meaning}")
        
        if len(phrases_data) > limit:
            print(f"  ... è¿˜æœ‰ {len(phrases_data) - limit} ä¸ªçŸ­è¯­æœªæ˜¾ç¤º")
    
    print()


def find_markdown_files(directory='.'):
    """æŸ¥æ‰¾å½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰markdownæ–‡ä»¶"""
    md_files = list(Path(directory).glob('*.md'))
    return [str(f) for f in md_files]


def batch_process():
    """æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶"""
    print("\nğŸ“ æ‰¹é‡å¤„ç†æ¨¡å¼")
    print("æ­£åœ¨æœç´¢å½“å‰ç›®å½•ä¸‹çš„ .md æ–‡ä»¶...")
    
    md_files = find_markdown_files()
    
    if not md_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½• .md æ–‡ä»¶")
        return
    
    print(f"\næ‰¾åˆ° {len(md_files)} ä¸ªæ–‡ä»¶ï¼š")
    for i, file in enumerate(md_files, 1):
        print(f"  [{i}] {file}")
    
    print("\næ˜¯å¦å¤„ç†æ‰€æœ‰æ–‡ä»¶ï¼Ÿ(y/n): ", end='')
    if input().strip().lower() != 'y':
        return
    
    mode = get_choice("\né€‰æ‹©æå–æ¨¡å¼ï¼š\n  [1] ä»…å•è¯\n  [2] å•è¯+è¯ä¹‰\n  [3] å•è¯+çŸ­è¯­+è¯ä¹‰\næ¨¡å¼: ", ['1', '2', '3'])
    
    success_count = 0
    for file in md_files:
        try:
            print(f"\nå¤„ç†: {file}")
            base_name = Path(file).stem
            
            if mode == '1':
                output = f"{base_name}_å•è¯.txt"
                extract_words_only(file, output, unique=True)
            elif mode == '2':
                output = f"{base_name}_å•è¯è¯ä¹‰.txt"
                extract_words_from_markdown(file, output, include_phrases=False)
            else:
                output = f"{base_name}_å®Œæ•´.txt"
                extract_words_from_markdown(file, output, include_phrases=True)
            
            success_count += 1
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
    
    print(f"\nâœ… æ‰¹é‡å¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç† {success_count}/{len(md_files)} ä¸ªæ–‡ä»¶")


def interactive_mode():
    """äº¤äº’å¼æ¨¡å¼"""
    print_header()
    
    while True:
        print_menu()
        print("é»˜è®¤é€‰æ‹©é€‰é¡¹1ï¼ˆæå–å•è¯+è‡ªåŠ¨æ ¸å¯¹ï¼‰")
        choice = input("è¯·é€‰æ‹© [0-4]ï¼ˆç›´æ¥å›è½¦é€‰æ‹©1ï¼‰: ").strip()
        
        # å¦‚æœç”¨æˆ·ç›´æ¥å›è½¦ï¼Œé»˜è®¤é€‰æ‹©1
        if not choice:
            choice = '1'
            print("å·²é€‰æ‹©é€‰é¡¹1")
        
        if choice not in ['0', '1', '2', '3', '4']:
            print("âŒ æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·è¾“å…¥ 0, 1, 2, 3, 4 ä¸­çš„ä¸€ä¸ª")
            continue
        
        if choice == '0':
            print("\nğŸ‘‹ å†è§ï¼")
            break
        
        if choice == '4':
            batch_process()
            input("\næŒ‰å›è½¦é”®ç»§ç»­...")
            continue
        
        # è·å–è¾“å…¥æ–‡ä»¶
        input_file = get_input_file()
        if not input_file:
            continue
        
        # æ ¹æ®æ¨¡å¼è®¾ç½®é»˜è®¤è¾“å‡ºæ–‡ä»¶å
        base_name = Path(input_file).stem
        
        if choice == '1':
            # ä»…å•è¯æ¨¡å¼ + è‡ªåŠ¨æ ¸å¯¹
            default_output = f"{base_name}_å•è¯.txt"
            output_file = get_output_file(default_output)
            
            print("\næ˜¯å¦å»é‡ï¼Ÿ(y/nï¼Œé»˜è®¤y): ", end='')
            unique = input().strip().lower() != 'n'
            
            print("\nğŸ”„ æ­£åœ¨æå–å•è¯...")
            try:
                words = extract_words_only(input_file, output_file, unique, auto_check=True)
                print(f"\nâœ… æˆåŠŸï¼å…±æå– {len(words)} ä¸ªå•è¯")
                
                # é¢„è§ˆï¼ˆå¦‚æœå·²ç»è¿›è¡Œäº†æ ¸å¯¹ï¼Œè¿™é‡Œå°±ä¸éœ€è¦å†é¢„è§ˆäº†ï¼‰
                if not os.path.exists(output_file.replace('.txt', '_check_detail_').replace('.txt', '') + '*.txt'):
                    print("\nå‰10ä¸ªå•è¯ï¼š")
                    for i, word in enumerate(words[:10], 1):
                        print(f"  {i}. {word}")
                    if len(words) > 10:
                        print(f"  ... è¿˜æœ‰ {len(words) - 10} ä¸ª")
                
            except Exception as e:
                print(f"\nâŒ æå–å¤±è´¥: {e}")
        
        elif choice == '2':
            # å•è¯+è¯ä¹‰æ¨¡å¼
            default_output = f"{base_name}_å•è¯è¯ä¹‰.txt"
            output_file = get_output_file(default_output)
            
            print("\nğŸ”„ æ­£åœ¨æå–å•è¯...")
            try:
                words_data = extract_words_from_markdown(input_file, output_file, include_phrases=False)
                print(f"\nâœ… æˆåŠŸï¼")
                preview_results(words_data)
            except Exception as e:
                print(f"\nâŒ æå–å¤±è´¥: {e}")
        
        elif choice == '3':
            # å•è¯+çŸ­è¯­+è¯ä¹‰æ¨¡å¼
            default_output = f"{base_name}_å®Œæ•´.txt"
            output_file = get_output_file(default_output)
            
            print("\nğŸ”„ æ­£åœ¨æå–å•è¯å’ŒçŸ­è¯­...")
            try:
                words_data, phrases_data = extract_words_from_markdown(input_file, output_file, include_phrases=True)
                print(f"\nâœ… æˆåŠŸï¼")
                preview_results(words_data, phrases_data)
            except Exception as e:
                print(f"\nâŒ æå–å¤±è´¥: {e}")
        
        input("\nâœ¨ æŒ‰å›è½¦é”®ç»§ç»­...")


if __name__ == '__main__':
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        # å‘½ä»¤è¡Œæ¨¡å¼
        parser = argparse.ArgumentParser(description='ä»markdownæ ¼å¼çš„å•è¯æœ¬ä¸­æå–å•è¯')
        parser.add_argument('input_file', help='è¾“å…¥çš„markdownæ–‡ä»¶è·¯å¾„')
        parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
        parser.add_argument('-m', '--mode', choices=['full', 'words_only'], default='full',
                            help='æå–æ¨¡å¼ï¼šfull=å®Œæ•´ä¿¡æ¯ï¼Œwords_only=ä»…å•è¯')
        parser.add_argument('-p', '--phrases', action='store_true',
                            help='æ˜¯å¦åŒ…å«çŸ­è¯­ï¼ˆä»…åœ¨fullæ¨¡å¼ä¸‹æœ‰æ•ˆï¼‰')
        parser.add_argument('--no-unique', action='store_true',
                            help='ä¸å»é‡ï¼ˆä»…åœ¨words_onlyæ¨¡å¼ä¸‹æœ‰æ•ˆï¼‰')
        
        args = parser.parse_args()
        
        # è®¾ç½®é»˜è®¤è¾“å‡ºæ–‡ä»¶å
        if not args.output:
            if args.mode == 'full':
                args.output = 'extracted_words_full.txt'
            else:
                args.output = 'extracted_words.txt'
        
        # æ‰§è¡Œæå–
        if args.mode == 'full':
            extract_words_from_markdown(args.input_file, args.output, args.phrases)
        else:
            extract_words_only(args.input_file, args.output, not args.no_unique)
        
        print("\næå–å®Œæˆï¼")
    else:
        # äº¤äº’å¼æ¨¡å¼
        try:
            interactive_mode()
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")

